$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json
environment:
  python_requirements_txt: requirements.txt
inputs:
  chat_history:
    type: list
    default: []
  question:
    type: string
    default: What is ChatGPT?
    is_chat_input: true
outputs:
  answer:
    type: string
    reference: ${augmented_chat.output}
    is_chat_output: true
nodes:
- name: extract_query_from_question
  use_variants: true
- name: augmented_chat
  type: llm
  source:
    type: code
    path: augmented_chat.jinja2
  inputs:
    deployment_name: gpt-35-turbo-16k
    model: gpt-3.5-turbo
    temperature: 0.8
    question: ${inputs.question}
    chat_history: ${inputs.chat_history}
    contexts: ${extract_query_from_question.output}
  connection: AOAI_KOREA
  api: chat
node_variants:
  extract_query_from_question:
    default_variant_id: variant_0
    variants:
      variant_0:
        node:
          type: llm
          source:
            type: code
            path: extract_query_from_question.jinja2
          inputs:
            deployment_name: gpt-35-turbo
            model: gpt-3.5-turbo
            temperature: 0.7
            top_p: 1
            max_tokens: 256
            presence_penalty: 0
            frequency_penalty: 0
            question: ${inputs.question}
            chat_history: ${inputs.chat_history}
          connection: AOAI_KOREA
          api: chat
      variant_1:
        node:
          type: llm
          source:
            type: code
            path: extract_query_from_question_variant_1.jinja2
          inputs:
            deployment_name: gpt-35-turbo
            model: gpt-3.5-turbo
            temperature: 0.7
            top_p: 1
            max_tokens: 256
            presence_penalty: 0
            frequency_penalty: 0
            question: ${inputs.question}
            chat_history: ${inputs.chat_history}
          connection: AOAI_KOREA
          api: chat
